version: '3.8'

services:
  # MLflow Tracking Server
  mlflow-server:
    build:
      context: ../../
      dockerfile: deployment/docker/Dockerfile
      target: mlflow-server
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/app/mlruns
      - ./models:/app/models
    environment:
      - MLFLOW_BACKEND_STORE_URI=file:./mlruns
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=./mlruns
    networks:
      - mlflow-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # FastAPI Model Serving
  fastapi-app:
    build:
      context: ../../
      dockerfile: deployment/docker/Dockerfile
      target: fastapi
    ports:
      - "8000:8000"
    volumes:
      - ./mlruns:/app/mlruns
      - ./models:/app/models
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
    depends_on:
      - mlflow-server
    networks:
      - mlflow-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Streamlit UI
  streamlit-app:
    build:
      context: ../../
      dockerfile: deployment/docker/Dockerfile
      target: streamlit
    ports:
      - "8501:8501"
    environment:
      - API_BASE_URL=http://fastapi-app:8000
    depends_on:
      - fastapi-app
    networks:
      - mlflow-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Training Service (run on demand)
  training:
    build:
      context: ../../
      dockerfile: deployment/docker/Dockerfile
      target: training
    volumes:
      - ./mlruns:/app/mlruns
      - ./models:/app/models
      - ./data:/app/data
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
    depends_on:
      - mlflow-server
    networks:
      - mlflow-network
    profiles:
      - training

  # Development Environment
  development:
    build:
      context: ../../
      dockerfile: deployment/docker/Dockerfile
      target: base
    ports:
      - "8888:8888"  # Jupyter
      - "8080:8080"  # Additional dev port
    volumes:
      - .:/app
      - ./mlruns:/app/mlruns
      - ./models:/app/models
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
      - JUPYTER_ENABLE_LAB=yes
    depends_on:
      - mlflow-server
    networks:
      - mlflow-network
    command: jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root
    profiles:
      - dev

networks:
  mlflow-network:
    driver: bridge

volumes:
  mlruns-data:
  models-data:
